\section{Заключение}
В ходе работы были собраны основные статьи и технологии, отметившиеся в сфере решения задач обработки ествественного языка. Подробно описана проблематика и специфика задач этой области. Сформулированы основные свойства вложенных многомерных представлений данных в текстовой модальности, разобраны токенизация и векторизация текста.
\newline
Был сделал обзор истории развития архитектур, применяемых в области NLP. Изучена парадигма проектирования сетей "энкодер-декодер", общая методология работы с данными неопределенной размерности и механизм внимания, а также архитектура "трансформер" на его основе. Разобрана технология претренеровки двунаправленных трансформеров для понимая текста.
\newline
Используя фреймворки pytorch, numpy и hugging face transformers была решена задача бинарной классификации токенов на медецинском датасете NBME. Обучение позволило получить модель с показателем метрики в ~10\% окрестности текущего SOTA решения, пригодную для дальнейшей интерпретации.
\newline
При помощи выбранной методики SHAP были проанализированы взаимосвязи между токенами одной последовательности при обработке натренерованной моделью. Был предложен метод визуализации на основе матриц значений SHAP, показывающий контекстуальную роль токенов. Также метод предпологает возможность дальнейшего соотнесения полученных зависимостей с оригинальными токенами и словами, то есть возможность восстановить логику принятия решения алгоритмом.